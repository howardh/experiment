<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>experiment.hyperparam.search API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>experiment.hyperparam.search</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from abc import ABC, abstractmethod
from typing import Callable
from collections import defaultdict
from collections.abc import Mapping
import itertools
import numpy as np
import os
import dill

from experiment import Experiment, ExperimentRunner
from experiment.utils import find_next_free_dir
from .distributions import Distribution, Constant, LogUniform

##################################################

def normalize_search_space(search_space):
    def normalize(x):
        if isinstance(x,Distribution):
            return x
        else:
            return Constant(x)
    return {k:normalize(v) for k,v in search_space.items()}

def serializable_search_space(search_space):
    def serialize(x):
        if isinstance(x,Distribution):
            return str(x)
        else:
            return str(Constant(x))
    return {k:serialize(v) for k,v in search_space.items()}

def unserializable_search_space(search_space):
    def unserialize(x):
        return exec(x)
    return {k:unserialize(v) for k,v in search_space.items()}

def search_space_vector_keys(search_space):
    keys = []
    for k,v in search_space.items():
        if isinstance(v,Distribution) and not isinstance(v,Constant):
            keys.append(k)
    keys = sorted(keys)
    return keys

def search_space_bounds(search_space):
    keys = search_space_vector_keys(search_space)
    bounds = []
    for k in keys:
        dist = search_space[k]
        bounds.append((dist.min_val,dist.max_val))
    return bounds

def search_space_sample(search_space):
    return {k:v.sample() for k,v in search_space.items()}

def config_dict_to_vector(search_space, config):
    keys = search_space_vector_keys(search_space)
    return [config[k] for k in keys]

def vector_to_config_dict(search_space, vec):
    keys = search_space_vector_keys(search_space)
    config = {
            **search_space
    }
    for k,v in search_space.items():
        if isinstance(v,Constant):
            config[k] = v.sample()
    for k,v in zip(keys,vec):
        if isinstance(search_space[k], LogUniform):
            config[k] = np.exp(v)
        else:
            config[k] = v
    return config

##################################################

class Search(ABC):
    def __init__(self, cls,
            search_space: Mapping,
            maximize: bool = False,
            **exp_runner_kwargs):
        &#34;&#34;&#34;
        Args:
            cls:
                Experiment class for the experiment to be run.
            search_space:
            score: 
                Function that returns a score that is to be optimized.
            maximize:
                If set to True, then the search will seek to maximize the score function instead of minimizing.
        &#34;&#34;&#34;
        self.cls = cls
        self.search_space = normalize_search_space(search_space)
        self.maximize = maximize
        self.exp_runner_kwargs = exp_runner_kwargs

class GridSearch(Search):
    def __init__(self, cls,
            search_space: Mapping,
            root_directory: str = &#39;./results&#39;,
            output_directory: str = None,
            **exp_runner_kwargs):
        &#34;&#34;&#34;
        Args:
            root_directory
                If specified, then a subdirectory will be created within the root directory, and all output for the gridsearch will be placed in the newly-created subdirectory.
            output_directory
                If specified, then all output for the gridsearch will be placedin this directory.
                Takes precedence over `root_directory` if both are specified.
        &#34;&#34;&#34;
        super().__init__(cls, search_space, **exp_runner_kwargs)
        self.root_directory = root_directory
        self.directory = find_next_free_dir(
                self.root_directory, &#39;Gridsearch-{}-%d&#39;.format(cls.__name__))
    def run(self):
        keys = self.search_space.keys()
        all_vals = list(itertools.product(*[self.search_space[k].linspace() for k in keys]))
        for i,vals in enumerate(all_vals):
            config = {k:v for k,v in zip(keys,vals)}
            exp = ExperimentRunner(self.cls,
                    root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                    config=config, **self.exp_runner_kwargs)
            exp.run()

class RandomSearch(Search):
    def __init__(self, cls,
            search_space: Mapping,
            name: str = None,
            root_directory: str = &#39;./results&#39;,
            output_directory: str = None,
            **exp_runner_kwargs):
        &#34;&#34;&#34;
        Args:
            root_directory
                If specified, then a subdirectory will be created within the root directory, and all output for the gridsearch will be placed in the newly-created subdirectory.
            output_directory
                If specified, then all output for the gridsearch will be placedin this directory.
                Takes precedence over `root_directory` if both are specified.
        &#34;&#34;&#34;
        super().__init__(cls, search_space, **exp_runner_kwargs)
        if name is None:
            name = &#39;RandomSearch-%s&#39; % cls.__name__
        self.root_directory = root_directory
        self.directory = find_next_free_dir(
                self.root_directory, &#39;{}-%d&#39;.format(name))
        self.search_space = normalize_search_space(search_space)
    def run(self):
        for _ in range(5):
            config = {k:v.sample() for k,v in self.search_space.items()}
            exp = ExperimentRunner(self.cls,
                    root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                    config=config, **self.exp_runner_kwargs)
            exp.run()

class BayesianOptimizationSearch(Search):
    def __init__(self, cls,
            search_space: Mapping,
            score_fn: Callable[[Experiment],int],
            name: str = None,
            search_budget: int = 5,
            root_directory: str = &#39;./results&#39;,
            output_directory: str = None,
            **exp_runner_kwargs):
        super().__init__(cls, search_space, **exp_runner_kwargs)
        if name is None:
            name = &#39;BayesianOptimizationSearch-%s&#39; % cls.__name__
        self.score_fn = score_fn
        self.search_budget = search_budget
        self.root_directory = root_directory
        self.directory = find_next_free_dir(
                self.root_directory, &#39;{}-%d&#39;.format(name))
        self.search_space = normalize_search_space(search_space)
    def run(self):
        import skopt
        from skopt import gp_minimize
        # Bounds
        bounds = search_space_bounds(self.search_space)
        # Objective function
        def objective_fn(x):
            config = vector_to_config_dict(self.search_space, x)
            exp = ExperimentRunner(self.cls,
                    root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                    config=config, **self.exp_runner_kwargs)
            exp.run()
            return self.score_fn(exp.exp)
        # Perform search
        results = gp_minimize(
                func=objective_fn,
                dimensions=bounds,
                acq_func=&#39;EI&#39;,
                n_calls=self.search_budget,
                n_random_starts=3
        )

##################################################

class Analysis(ABC):
    def best_config(self):
        pass
    def best_score(self):
        pass

class SimpleAnalysis(Analysis):
    &#34;&#34;&#34; Treat all runs as independent runs. &#34;&#34;&#34;
    def __init__(self, cls,
            score_fn: Callable[[Experiment],int],
            maximize=False,
            directory: str = None):
        self.directory = directory
        self.score_fn = score_fn
        self.maximize = maximize
        self.cls = cls
        self.results = None
        self.sorted_results = None
    def _load_results(self):
        self.results = []
        for name in os.listdir(self.directory):
            checkpoint_filename = os.path.join(self.directory,name,&#39;checkpoint.pkl&#39;)
            with open(checkpoint_filename,&#39;rb&#39;) as f:
                checkpoint = dill.load(f)
            config = checkpoint[&#39;args&#39;][&#39;config&#39;]
            exp = self.cls()
            exp.load_state_dict(checkpoint[&#39;exp&#39;])
            self.results.append((self.score_fn(exp),config))
    def _sort_results(self):
        if self.results is None:
            self._load_results()
        if self.sorted_results is not None:
            return
        sorted_results = sorted(
                self.results,
                key=lambda x: x[0],
                reverse=self.maximize
        )
        self.sorted_results = sorted_results
    def get_best_config(self):
        self._sort_results()
        score,config = self.sorted_results[0]
        return config
    def get_best_score(self):
        self._sort_results()
        score,config = self.sorted_results[0]
        return score

class GroupedAnalysis(Analysis):
    &#34;&#34;&#34; Group together runs that use the same hyperparameters. &#34;&#34;&#34;
    def __init__(self, cls,
            score_fn: Callable[[Experiment],int],
            maximize=False,
            directory: str = None):
        self.directory = directory
        self.score_fn = score_fn
        self.maximize = maximize
        self.cls = cls
        self.results = None
        self.sorted_results = None
    def _load_results(self):
        self.results = defaultdict(lambda: [])
        for name in os.listdir(self.directory):
            checkpoint_filename = os.path.join(self.directory,name,&#39;checkpoint.pkl&#39;)
            with open(checkpoint_filename,&#39;rb&#39;) as f:
                checkpoint = dill.load(f)
            config = checkpoint[&#39;args&#39;][&#39;config&#39;]
            exp = self.cls()
            exp.load_state_dict(checkpoint[&#39;exp&#39;])
            key = frozenset(config.items())
            self.results[key].append(self.score_fn(exp))
    def _sort_results(self):
        if self.results is None:
            self._load_results()
        if self.sorted_results is not None:
            return
        sorted_results = sorted(
                self.results.items(),
                key=lambda x: np.mean(x[1]),
                reverse=self.maximize
        )
        self.sorted_results = sorted_results
    def get_best_config(self):
        self._sort_results()
        config,score = self.sorted_results[0]
        return dict(config)
    def get_best_score(self):
        self._sort_results()
        config,score = self.sorted_results[0]
        return score

class GaussianProcessAnalysis(Analysis):
    &#34;&#34;&#34; Fit a Gaussian Process to the return. &#34;&#34;&#34;
    def __init__(self, cls,
            score_fn: Callable[[Experiment],int],
            search_space: Mapping,
            maximize=False,
            directory: str = None):
        self.directory = directory
        self.score_fn = score_fn
        self.search_space = search_space
        self.maximize = maximize
        self.cls = cls
        self.results = None
        self.best_result = None
    def _load_results(self):
        self.results = []
        for name in os.listdir(self.directory):
            checkpoint_filename = os.path.join(self.directory,name,&#39;checkpoint.pkl&#39;)
            with open(checkpoint_filename,&#39;rb&#39;) as f:
                checkpoint = dill.load(f)
            config = checkpoint[&#39;args&#39;][&#39;config&#39;]
            exp = self.cls()
            exp.load_state_dict(checkpoint[&#39;exp&#39;])
            self.results.append((self.score_fn(exp), config))
    def _find_optimum(self):
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import Matern
        from scipy.optimize import minimize
        # Load if needed
        if self.results is None:
            self._load_results()
        # Bounds
        bounds = search_space_bounds(self.search_space)
        # Initial Guess
        x0 = config_dict_to_vector(
                self.search_space,
                search_space_sample(self.search_space)
        )
        # Extract data
        x = [[config[k] for k in keys] for _,config in self.results]
        y = [score for score,_ in self.results]
        # Fit GP
        kernel = Matern()
        gpr = GaussianProcessRegressor(kernel=kernel)
        gpr.fit(x,y)
        # Find optimum
        opt_result = minimize(
                fun=lambda x: gpr.predict([x]),
                method=&#39;L-BFGS-B&#39;,
                bounds=bounds,
                x0=x0
        )
        # Convert back to config
        best_config = vector_to_config_dict(self.search_space, opt_result.x)
        # Save optimum
        self.best_result = (opt_result.fun.item(), best_config)
    def get_best_config(self):
        self._find_optimum()
        score,config = self.best_result
        return config
    def get_best_score(self):
        self._find_optimum()
        score,config = self.best_result
        return score</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="experiment.hyperparam.search.config_dict_to_vector"><code class="name flex">
<span>def <span class="ident">config_dict_to_vector</span></span>(<span>search_space, config)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def config_dict_to_vector(search_space, config):
    keys = search_space_vector_keys(search_space)
    return [config[k] for k in keys]</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.normalize_search_space"><code class="name flex">
<span>def <span class="ident">normalize_search_space</span></span>(<span>search_space)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_search_space(search_space):
    def normalize(x):
        if isinstance(x,Distribution):
            return x
        else:
            return Constant(x)
    return {k:normalize(v) for k,v in search_space.items()}</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.search_space_bounds"><code class="name flex">
<span>def <span class="ident">search_space_bounds</span></span>(<span>search_space)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search_space_bounds(search_space):
    keys = search_space_vector_keys(search_space)
    bounds = []
    for k in keys:
        dist = search_space[k]
        bounds.append((dist.min_val,dist.max_val))
    return bounds</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.search_space_sample"><code class="name flex">
<span>def <span class="ident">search_space_sample</span></span>(<span>search_space)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search_space_sample(search_space):
    return {k:v.sample() for k,v in search_space.items()}</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.search_space_vector_keys"><code class="name flex">
<span>def <span class="ident">search_space_vector_keys</span></span>(<span>search_space)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search_space_vector_keys(search_space):
    keys = []
    for k,v in search_space.items():
        if isinstance(v,Distribution) and not isinstance(v,Constant):
            keys.append(k)
    keys = sorted(keys)
    return keys</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.serializable_search_space"><code class="name flex">
<span>def <span class="ident">serializable_search_space</span></span>(<span>search_space)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serializable_search_space(search_space):
    def serialize(x):
        if isinstance(x,Distribution):
            return str(x)
        else:
            return str(Constant(x))
    return {k:serialize(v) for k,v in search_space.items()}</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.unserializable_search_space"><code class="name flex">
<span>def <span class="ident">unserializable_search_space</span></span>(<span>search_space)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unserializable_search_space(search_space):
    def unserialize(x):
        return exec(x)
    return {k:unserialize(v) for k,v in search_space.items()}</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.vector_to_config_dict"><code class="name flex">
<span>def <span class="ident">vector_to_config_dict</span></span>(<span>search_space, vec)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vector_to_config_dict(search_space, vec):
    keys = search_space_vector_keys(search_space)
    config = {
            **search_space
    }
    for k,v in search_space.items():
        if isinstance(v,Constant):
            config[k] = v.sample()
    for k,v in zip(keys,vec):
        if isinstance(search_space[k], LogUniform):
            config[k] = np.exp(v)
        else:
            config[k] = v
    return config</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="experiment.hyperparam.search.Analysis"><code class="flex name class">
<span>class <span class="ident">Analysis</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Analysis(ABC):
    def best_config(self):
        pass
    def best_score(self):
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.GaussianProcessAnalysis" href="#experiment.hyperparam.search.GaussianProcessAnalysis">GaussianProcessAnalysis</a></li>
<li><a title="experiment.hyperparam.search.GroupedAnalysis" href="#experiment.hyperparam.search.GroupedAnalysis">GroupedAnalysis</a></li>
<li><a title="experiment.hyperparam.search.SimpleAnalysis" href="#experiment.hyperparam.search.SimpleAnalysis">SimpleAnalysis</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.Analysis.best_config"><code class="name flex">
<span>def <span class="ident">best_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_config(self):
    pass</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.Analysis.best_score"><code class="name flex">
<span>def <span class="ident">best_score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_score(self):
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="experiment.hyperparam.search.BayesianOptimizationSearch"><code class="flex name class">
<span>class <span class="ident">BayesianOptimizationSearch</span></span>
<span>(</span><span>cls, search_space: collections.abc.Mapping, score_fn: Callable[[<a title="experiment.Experiment" href="../index.html#experiment.Experiment">Experiment</a>], int], name: str = None, search_budget: int = 5, root_directory: str = './results', output_directory: str = None, **exp_runner_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<h2 id="args">Args</h2>
<dl>
<dt>cls:</dt>
<dt>Experiment class for the experiment to be run.</dt>
<dt>search_space:</dt>
<dt><strong><code>score</code></strong></dt>
<dd>Function that returns a score that is to be optimized.</dd>
</dl>
<p>maximize:
If set to True, then the search will seek to maximize the score function instead of minimizing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BayesianOptimizationSearch(Search):
    def __init__(self, cls,
            search_space: Mapping,
            score_fn: Callable[[Experiment],int],
            name: str = None,
            search_budget: int = 5,
            root_directory: str = &#39;./results&#39;,
            output_directory: str = None,
            **exp_runner_kwargs):
        super().__init__(cls, search_space, **exp_runner_kwargs)
        if name is None:
            name = &#39;BayesianOptimizationSearch-%s&#39; % cls.__name__
        self.score_fn = score_fn
        self.search_budget = search_budget
        self.root_directory = root_directory
        self.directory = find_next_free_dir(
                self.root_directory, &#39;{}-%d&#39;.format(name))
        self.search_space = normalize_search_space(search_space)
    def run(self):
        import skopt
        from skopt import gp_minimize
        # Bounds
        bounds = search_space_bounds(self.search_space)
        # Objective function
        def objective_fn(x):
            config = vector_to_config_dict(self.search_space, x)
            exp = ExperimentRunner(self.cls,
                    root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                    config=config, **self.exp_runner_kwargs)
            exp.run()
            return self.score_fn(exp.exp)
        # Perform search
        results = gp_minimize(
                func=objective_fn,
                dimensions=bounds,
                acq_func=&#39;EI&#39;,
                n_calls=self.search_budget,
                n_random_starts=3
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.Search" href="#experiment.hyperparam.search.Search">Search</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.BayesianOptimizationSearch.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    import skopt
    from skopt import gp_minimize
    # Bounds
    bounds = search_space_bounds(self.search_space)
    # Objective function
    def objective_fn(x):
        config = vector_to_config_dict(self.search_space, x)
        exp = ExperimentRunner(self.cls,
                root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                config=config, **self.exp_runner_kwargs)
        exp.run()
        return self.score_fn(exp.exp)
    # Perform search
    results = gp_minimize(
            func=objective_fn,
            dimensions=bounds,
            acq_func=&#39;EI&#39;,
            n_calls=self.search_budget,
            n_random_starts=3
    )</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="experiment.hyperparam.search.GaussianProcessAnalysis"><code class="flex name class">
<span>class <span class="ident">GaussianProcessAnalysis</span></span>
<span>(</span><span>cls, score_fn: Callable[[<a title="experiment.Experiment" href="../index.html#experiment.Experiment">Experiment</a>], int], search_space: collections.abc.Mapping, maximize=False, directory: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fit a Gaussian Process to the return.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GaussianProcessAnalysis(Analysis):
    &#34;&#34;&#34; Fit a Gaussian Process to the return. &#34;&#34;&#34;
    def __init__(self, cls,
            score_fn: Callable[[Experiment],int],
            search_space: Mapping,
            maximize=False,
            directory: str = None):
        self.directory = directory
        self.score_fn = score_fn
        self.search_space = search_space
        self.maximize = maximize
        self.cls = cls
        self.results = None
        self.best_result = None
    def _load_results(self):
        self.results = []
        for name in os.listdir(self.directory):
            checkpoint_filename = os.path.join(self.directory,name,&#39;checkpoint.pkl&#39;)
            with open(checkpoint_filename,&#39;rb&#39;) as f:
                checkpoint = dill.load(f)
            config = checkpoint[&#39;args&#39;][&#39;config&#39;]
            exp = self.cls()
            exp.load_state_dict(checkpoint[&#39;exp&#39;])
            self.results.append((self.score_fn(exp), config))
    def _find_optimum(self):
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import Matern
        from scipy.optimize import minimize
        # Load if needed
        if self.results is None:
            self._load_results()
        # Bounds
        bounds = search_space_bounds(self.search_space)
        # Initial Guess
        x0 = config_dict_to_vector(
                self.search_space,
                search_space_sample(self.search_space)
        )
        # Extract data
        x = [[config[k] for k in keys] for _,config in self.results]
        y = [score for score,_ in self.results]
        # Fit GP
        kernel = Matern()
        gpr = GaussianProcessRegressor(kernel=kernel)
        gpr.fit(x,y)
        # Find optimum
        opt_result = minimize(
                fun=lambda x: gpr.predict([x]),
                method=&#39;L-BFGS-B&#39;,
                bounds=bounds,
                x0=x0
        )
        # Convert back to config
        best_config = vector_to_config_dict(self.search_space, opt_result.x)
        # Save optimum
        self.best_result = (opt_result.fun.item(), best_config)
    def get_best_config(self):
        self._find_optimum()
        score,config = self.best_result
        return config
    def get_best_score(self):
        self._find_optimum()
        score,config = self.best_result
        return score</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.Analysis" href="#experiment.hyperparam.search.Analysis">Analysis</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.GaussianProcessAnalysis.get_best_config"><code class="name flex">
<span>def <span class="ident">get_best_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_config(self):
    self._find_optimum()
    score,config = self.best_result
    return config</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.GaussianProcessAnalysis.get_best_score"><code class="name flex">
<span>def <span class="ident">get_best_score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_score(self):
    self._find_optimum()
    score,config = self.best_result
    return score</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="experiment.hyperparam.search.GridSearch"><code class="flex name class">
<span>class <span class="ident">GridSearch</span></span>
<span>(</span><span>cls, search_space: collections.abc.Mapping, root_directory: str = './results', output_directory: str = None, **exp_runner_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<h2 id="args">Args</h2>
<p>root_directory
If specified, then a subdirectory will be created within the root directory, and all output for the gridsearch will be placed in the newly-created subdirectory.
output_directory
If specified, then all output for the gridsearch will be placedin this directory.
Takes precedence over <code>root_directory</code> if both are specified.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GridSearch(Search):
    def __init__(self, cls,
            search_space: Mapping,
            root_directory: str = &#39;./results&#39;,
            output_directory: str = None,
            **exp_runner_kwargs):
        &#34;&#34;&#34;
        Args:
            root_directory
                If specified, then a subdirectory will be created within the root directory, and all output for the gridsearch will be placed in the newly-created subdirectory.
            output_directory
                If specified, then all output for the gridsearch will be placedin this directory.
                Takes precedence over `root_directory` if both are specified.
        &#34;&#34;&#34;
        super().__init__(cls, search_space, **exp_runner_kwargs)
        self.root_directory = root_directory
        self.directory = find_next_free_dir(
                self.root_directory, &#39;Gridsearch-{}-%d&#39;.format(cls.__name__))
    def run(self):
        keys = self.search_space.keys()
        all_vals = list(itertools.product(*[self.search_space[k].linspace() for k in keys]))
        for i,vals in enumerate(all_vals):
            config = {k:v for k,v in zip(keys,vals)}
            exp = ExperimentRunner(self.cls,
                    root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                    config=config, **self.exp_runner_kwargs)
            exp.run()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.Search" href="#experiment.hyperparam.search.Search">Search</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.GridSearch.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    keys = self.search_space.keys()
    all_vals = list(itertools.product(*[self.search_space[k].linspace() for k in keys]))
    for i,vals in enumerate(all_vals):
        config = {k:v for k,v in zip(keys,vals)}
        exp = ExperimentRunner(self.cls,
                root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                config=config, **self.exp_runner_kwargs)
        exp.run()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="experiment.hyperparam.search.GroupedAnalysis"><code class="flex name class">
<span>class <span class="ident">GroupedAnalysis</span></span>
<span>(</span><span>cls, score_fn: Callable[[<a title="experiment.Experiment" href="../index.html#experiment.Experiment">Experiment</a>], int], maximize=False, directory: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Group together runs that use the same hyperparameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GroupedAnalysis(Analysis):
    &#34;&#34;&#34; Group together runs that use the same hyperparameters. &#34;&#34;&#34;
    def __init__(self, cls,
            score_fn: Callable[[Experiment],int],
            maximize=False,
            directory: str = None):
        self.directory = directory
        self.score_fn = score_fn
        self.maximize = maximize
        self.cls = cls
        self.results = None
        self.sorted_results = None
    def _load_results(self):
        self.results = defaultdict(lambda: [])
        for name in os.listdir(self.directory):
            checkpoint_filename = os.path.join(self.directory,name,&#39;checkpoint.pkl&#39;)
            with open(checkpoint_filename,&#39;rb&#39;) as f:
                checkpoint = dill.load(f)
            config = checkpoint[&#39;args&#39;][&#39;config&#39;]
            exp = self.cls()
            exp.load_state_dict(checkpoint[&#39;exp&#39;])
            key = frozenset(config.items())
            self.results[key].append(self.score_fn(exp))
    def _sort_results(self):
        if self.results is None:
            self._load_results()
        if self.sorted_results is not None:
            return
        sorted_results = sorted(
                self.results.items(),
                key=lambda x: np.mean(x[1]),
                reverse=self.maximize
        )
        self.sorted_results = sorted_results
    def get_best_config(self):
        self._sort_results()
        config,score = self.sorted_results[0]
        return dict(config)
    def get_best_score(self):
        self._sort_results()
        config,score = self.sorted_results[0]
        return score</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.Analysis" href="#experiment.hyperparam.search.Analysis">Analysis</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.GroupedAnalysis.get_best_config"><code class="name flex">
<span>def <span class="ident">get_best_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_config(self):
    self._sort_results()
    config,score = self.sorted_results[0]
    return dict(config)</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.GroupedAnalysis.get_best_score"><code class="name flex">
<span>def <span class="ident">get_best_score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_score(self):
    self._sort_results()
    config,score = self.sorted_results[0]
    return score</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="experiment.hyperparam.search.RandomSearch"><code class="flex name class">
<span>class <span class="ident">RandomSearch</span></span>
<span>(</span><span>cls, search_space: collections.abc.Mapping, name: str = None, root_directory: str = './results', output_directory: str = None, **exp_runner_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<h2 id="args">Args</h2>
<p>root_directory
If specified, then a subdirectory will be created within the root directory, and all output for the gridsearch will be placed in the newly-created subdirectory.
output_directory
If specified, then all output for the gridsearch will be placedin this directory.
Takes precedence over <code>root_directory</code> if both are specified.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RandomSearch(Search):
    def __init__(self, cls,
            search_space: Mapping,
            name: str = None,
            root_directory: str = &#39;./results&#39;,
            output_directory: str = None,
            **exp_runner_kwargs):
        &#34;&#34;&#34;
        Args:
            root_directory
                If specified, then a subdirectory will be created within the root directory, and all output for the gridsearch will be placed in the newly-created subdirectory.
            output_directory
                If specified, then all output for the gridsearch will be placedin this directory.
                Takes precedence over `root_directory` if both are specified.
        &#34;&#34;&#34;
        super().__init__(cls, search_space, **exp_runner_kwargs)
        if name is None:
            name = &#39;RandomSearch-%s&#39; % cls.__name__
        self.root_directory = root_directory
        self.directory = find_next_free_dir(
                self.root_directory, &#39;{}-%d&#39;.format(name))
        self.search_space = normalize_search_space(search_space)
    def run(self):
        for _ in range(5):
            config = {k:v.sample() for k,v in self.search_space.items()}
            exp = ExperimentRunner(self.cls,
                    root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                    config=config, **self.exp_runner_kwargs)
            exp.run()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.Search" href="#experiment.hyperparam.search.Search">Search</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.RandomSearch.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    for _ in range(5):
        config = {k:v.sample() for k,v in self.search_space.items()}
        exp = ExperimentRunner(self.cls,
                root_directory=os.path.join(self.directory,&#39;Experiments&#39;),
                config=config, **self.exp_runner_kwargs)
        exp.run()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="experiment.hyperparam.search.Search"><code class="flex name class">
<span>class <span class="ident">Search</span></span>
<span>(</span><span>cls, search_space: collections.abc.Mapping, maximize: bool = False, **exp_runner_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<h2 id="args">Args</h2>
<dl>
<dt>cls:</dt>
<dt>Experiment class for the experiment to be run.</dt>
<dt>search_space:</dt>
<dt><strong><code>score</code></strong></dt>
<dd>Function that returns a score that is to be optimized.</dd>
</dl>
<p>maximize:
If set to True, then the search will seek to maximize the score function instead of minimizing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Search(ABC):
    def __init__(self, cls,
            search_space: Mapping,
            maximize: bool = False,
            **exp_runner_kwargs):
        &#34;&#34;&#34;
        Args:
            cls:
                Experiment class for the experiment to be run.
            search_space:
            score: 
                Function that returns a score that is to be optimized.
            maximize:
                If set to True, then the search will seek to maximize the score function instead of minimizing.
        &#34;&#34;&#34;
        self.cls = cls
        self.search_space = normalize_search_space(search_space)
        self.maximize = maximize
        self.exp_runner_kwargs = exp_runner_kwargs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.BayesianOptimizationSearch" href="#experiment.hyperparam.search.BayesianOptimizationSearch">BayesianOptimizationSearch</a></li>
<li><a title="experiment.hyperparam.search.GridSearch" href="#experiment.hyperparam.search.GridSearch">GridSearch</a></li>
<li><a title="experiment.hyperparam.search.RandomSearch" href="#experiment.hyperparam.search.RandomSearch">RandomSearch</a></li>
</ul>
</dd>
<dt id="experiment.hyperparam.search.SimpleAnalysis"><code class="flex name class">
<span>class <span class="ident">SimpleAnalysis</span></span>
<span>(</span><span>cls, score_fn: Callable[[<a title="experiment.Experiment" href="../index.html#experiment.Experiment">Experiment</a>], int], maximize=False, directory: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Treat all runs as independent runs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleAnalysis(Analysis):
    &#34;&#34;&#34; Treat all runs as independent runs. &#34;&#34;&#34;
    def __init__(self, cls,
            score_fn: Callable[[Experiment],int],
            maximize=False,
            directory: str = None):
        self.directory = directory
        self.score_fn = score_fn
        self.maximize = maximize
        self.cls = cls
        self.results = None
        self.sorted_results = None
    def _load_results(self):
        self.results = []
        for name in os.listdir(self.directory):
            checkpoint_filename = os.path.join(self.directory,name,&#39;checkpoint.pkl&#39;)
            with open(checkpoint_filename,&#39;rb&#39;) as f:
                checkpoint = dill.load(f)
            config = checkpoint[&#39;args&#39;][&#39;config&#39;]
            exp = self.cls()
            exp.load_state_dict(checkpoint[&#39;exp&#39;])
            self.results.append((self.score_fn(exp),config))
    def _sort_results(self):
        if self.results is None:
            self._load_results()
        if self.sorted_results is not None:
            return
        sorted_results = sorted(
                self.results,
                key=lambda x: x[0],
                reverse=self.maximize
        )
        self.sorted_results = sorted_results
    def get_best_config(self):
        self._sort_results()
        score,config = self.sorted_results[0]
        return config
    def get_best_score(self):
        self._sort_results()
        score,config = self.sorted_results[0]
        return score</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="experiment.hyperparam.search.Analysis" href="#experiment.hyperparam.search.Analysis">Analysis</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="experiment.hyperparam.search.SimpleAnalysis.get_best_config"><code class="name flex">
<span>def <span class="ident">get_best_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_config(self):
    self._sort_results()
    score,config = self.sorted_results[0]
    return config</code></pre>
</details>
</dd>
<dt id="experiment.hyperparam.search.SimpleAnalysis.get_best_score"><code class="name flex">
<span>def <span class="ident">get_best_score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_score(self):
    self._sort_results()
    score,config = self.sorted_results[0]
    return score</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="experiment.hyperparam" href="index.html">experiment.hyperparam</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="experiment.hyperparam.search.config_dict_to_vector" href="#experiment.hyperparam.search.config_dict_to_vector">config_dict_to_vector</a></code></li>
<li><code><a title="experiment.hyperparam.search.normalize_search_space" href="#experiment.hyperparam.search.normalize_search_space">normalize_search_space</a></code></li>
<li><code><a title="experiment.hyperparam.search.search_space_bounds" href="#experiment.hyperparam.search.search_space_bounds">search_space_bounds</a></code></li>
<li><code><a title="experiment.hyperparam.search.search_space_sample" href="#experiment.hyperparam.search.search_space_sample">search_space_sample</a></code></li>
<li><code><a title="experiment.hyperparam.search.search_space_vector_keys" href="#experiment.hyperparam.search.search_space_vector_keys">search_space_vector_keys</a></code></li>
<li><code><a title="experiment.hyperparam.search.serializable_search_space" href="#experiment.hyperparam.search.serializable_search_space">serializable_search_space</a></code></li>
<li><code><a title="experiment.hyperparam.search.unserializable_search_space" href="#experiment.hyperparam.search.unserializable_search_space">unserializable_search_space</a></code></li>
<li><code><a title="experiment.hyperparam.search.vector_to_config_dict" href="#experiment.hyperparam.search.vector_to_config_dict">vector_to_config_dict</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="experiment.hyperparam.search.Analysis" href="#experiment.hyperparam.search.Analysis">Analysis</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.Analysis.best_config" href="#experiment.hyperparam.search.Analysis.best_config">best_config</a></code></li>
<li><code><a title="experiment.hyperparam.search.Analysis.best_score" href="#experiment.hyperparam.search.Analysis.best_score">best_score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.BayesianOptimizationSearch" href="#experiment.hyperparam.search.BayesianOptimizationSearch">BayesianOptimizationSearch</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.BayesianOptimizationSearch.run" href="#experiment.hyperparam.search.BayesianOptimizationSearch.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.GaussianProcessAnalysis" href="#experiment.hyperparam.search.GaussianProcessAnalysis">GaussianProcessAnalysis</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.GaussianProcessAnalysis.get_best_config" href="#experiment.hyperparam.search.GaussianProcessAnalysis.get_best_config">get_best_config</a></code></li>
<li><code><a title="experiment.hyperparam.search.GaussianProcessAnalysis.get_best_score" href="#experiment.hyperparam.search.GaussianProcessAnalysis.get_best_score">get_best_score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.GridSearch" href="#experiment.hyperparam.search.GridSearch">GridSearch</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.GridSearch.run" href="#experiment.hyperparam.search.GridSearch.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.GroupedAnalysis" href="#experiment.hyperparam.search.GroupedAnalysis">GroupedAnalysis</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.GroupedAnalysis.get_best_config" href="#experiment.hyperparam.search.GroupedAnalysis.get_best_config">get_best_config</a></code></li>
<li><code><a title="experiment.hyperparam.search.GroupedAnalysis.get_best_score" href="#experiment.hyperparam.search.GroupedAnalysis.get_best_score">get_best_score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.RandomSearch" href="#experiment.hyperparam.search.RandomSearch">RandomSearch</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.RandomSearch.run" href="#experiment.hyperparam.search.RandomSearch.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.Search" href="#experiment.hyperparam.search.Search">Search</a></code></h4>
</li>
<li>
<h4><code><a title="experiment.hyperparam.search.SimpleAnalysis" href="#experiment.hyperparam.search.SimpleAnalysis">SimpleAnalysis</a></code></h4>
<ul class="">
<li><code><a title="experiment.hyperparam.search.SimpleAnalysis.get_best_config" href="#experiment.hyperparam.search.SimpleAnalysis.get_best_config">get_best_config</a></code></li>
<li><code><a title="experiment.hyperparam.search.SimpleAnalysis.get_best_score" href="#experiment.hyperparam.search.SimpleAnalysis.get_best_score">get_best_score</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>